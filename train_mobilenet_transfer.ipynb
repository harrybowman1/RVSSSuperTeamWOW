{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see:\n",
    "https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py and \n",
    "https://pytorch.org/hub/pytorch_vision_mobilenet_v2/\n",
    "\n",
    "Datasets\n",
    "\n",
    "- data1... shitty run. The test set is a random subset\n",
    "- data2... less shitty run. Test-Data is the last frames\n",
    "- data5... good run with a little noise (wheel outside road)\n",
    "- data5_subset... subset of data5 to be used as a evaluation dataset\n",
    "- data6... perfrect run on the green data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Problem**: Acc konvergiert nicht\n",
    "\n",
    "\n",
    "# Mögliche Ursachen\n",
    "\n",
    "* Model\n",
    "    * kann icht sein, denn es funktioniert auch nicht mit Harry's Model, und er sagt, er bekommt mehr\n",
    "    * ich habe auch schon probiert, ein komplexeres FC-Modell zu nutzen, und das hat auch nicht geklappt\n",
    "* Training\n",
    "    * kann icht sein, denn der Train-Loop ist straight forward\n",
    "* Daten\n",
    "    * trainset und testset sind zu unterschiedlich\n",
    "* Berechnung der Acc.\n",
    "* auf den Daten ist gar keine Generalisierungsfähigkeit zu erwarten\n",
    "\n",
    "# Lösungen\n",
    "\n",
    "## Lösung 1\n",
    "* möglichst geradeaus fahren und kurz vor der Kurve drehen\n",
    "* data6 ist der beste DAtensatz bis jetzt\n",
    "* data5 ist auch nicht schlecht und geht in die Gegenrichtung von data6, die beiden Datensätze muss ich im folgenden benutzen\n",
    "=> mit dem neuen Datensatz und dem Modell von Harry erziele ich bessere Ergebnisse\n",
    "\n",
    "## Lösung 2\n",
    "* der Transfer funktioniert schlecht, da ich an einer zu späten stelle cutte\n",
    "* früher cutten\n",
    "\n",
    "TODO\n",
    "- [x] mein Modell langsam wieder einführen\n",
    "- [ ] alles auf dem Roboter testen\n",
    "- [ ] einen neuen Datensatz auf einer Schotterstraßenkombination testen\n",
    "- [ ] Hyperparameter weiter tweaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "TRAIN_DIR = 'data6'\n",
    "TEST_DIR = 'data5_subset'\n",
    "DOWNSIZE = (32, 32)\n",
    "HEIGHT = 240\n",
    "WIDTH = 320\n",
    "CROP_FRAC = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "mobilenet = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT)\n",
    "embedding_model = torch.nn.Sequential(*list(list(mobilenet.children())[0].children())[:2])\n",
    "embedding_model.eval()\n",
    "\n",
    "classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=1024, out_features=256, bias=True),\n",
    "    #torch.nn.Linear(in_features=384, out_features=256, bias=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=128, out_features=3, bias=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteerDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self,root_folder,img_ext = \".jpg\" , transform=None):\n",
    "        self.root_folder = root_folder\n",
    "        self.transform = transform        \n",
    "        self.img_ext = img_ext        \n",
    "        self.filenames = glob(path.join(self.root_folder,\"*\" + self.img_ext))            \n",
    "        self.totensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):        \n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        f = self.filenames[idx]        \n",
    "        img = Image.open(f)\n",
    "        \n",
    "        if self.transform == None:\n",
    "            img = self.totensor(img)\n",
    "        else:\n",
    "            img = self.transform(img)   \n",
    "        \n",
    "        if 'Ang' in f:\n",
    "            steering = f.split('Ang')[1][:-4]\n",
    "            steering = float(steering)\n",
    "        else:\n",
    "            steering = f.split(\"/\")[-1].split(self.img_ext)[0][6:]\n",
    "            if '-' in steering:\n",
    "                steering = steering.split('.')[-1]\n",
    "            steering = np.float32(steering)\n",
    "\n",
    "        if steering > 0:\n",
    "            simple_steering = 0\n",
    "        elif steering < 0:\n",
    "            simple_steering = 1\n",
    "        else:\n",
    "            simple_steering = 2\n",
    "    \n",
    "        sample = {\"image\":img , \"steering\":steering, \"simple_steering\": simple_steering}        \n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: transforms.functional.crop(x, int(HEIGHT/CROP_FRAC), 0, int(HEIGHT-HEIGHT/CROP_FRAC), WIDTH)),\n",
    "    transforms.Resize(DOWNSIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "trainset = SteerDataSet(TRAIN_DIR, \".jpg\", preprocess)\n",
    "testset = SteerDataSet(TEST_DIR, \".jpg\", preprocess)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(preds, label, bs):\n",
    "    return sum( [a.item() == b.item()  for (a, b) in zip(preds, label)] ) / bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRINT_FREQ = 20\n",
    "\n",
    "classifier.train()\n",
    "test_accuracies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 20):\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, s in enumerate(trainloader):\n",
    "        # bring data in right format\n",
    "        data = s['image']\n",
    "        label = s['simple_steering']\n",
    "        # label_onehot = torch.nn.functional.one_hot(label, num_classes = 3)\n",
    "\n",
    "        # apply embedding model\n",
    "        with torch.no_grad():\n",
    "            embeddings = torch.flatten(embedding_model(data), 1)\n",
    "        \n",
    "        # backprop classifier\n",
    "        optimizer.zero_grad()\n",
    "        output = classifier(embeddings)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update train-accuracy\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        this_acc = get_acc(pred, label, BATCH_SIZE)\n",
    "\n",
    "        running_loss = running_loss + loss.item()\n",
    "        running_acc = running_acc + this_acc\n",
    "\n",
    "        if i % PRINT_FREQ == PRINT_FREQ-1:\n",
    "            print(f\"epoch: {epoch},\\t item: {i+1},\\t loss:{running_loss:.3f},\\t acc: {running_acc/PRINT_FREQ:.2f}\")\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "\n",
    "    # TEST LOOP\n",
    "    print('test loop')\n",
    "    running_test_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, s in enumerate(testloader):\n",
    "            data = s['image']\n",
    "            label = s['simple_steering']\n",
    "\n",
    "            embeddings = torch.flatten(embedding_model(data), 1)       \n",
    "            output = classifier(embeddings)\n",
    "            pred = torch.argmax(output, dim=1)\n",
    "            test_acc = get_acc(pred, label, BATCH_SIZE)\n",
    "            running_test_acc = test_acc + running_test_acc\n",
    "\n",
    "        print(f\"test acc: {running_test_acc / len(testloader):.2f}\")\n",
    "        test_accuracies.append(running_test_acc / len(testloader))\n",
    "\n",
    "    torch.save(classifier.state_dict(), f'class_params_e{epoch}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(test_accuracies)\n",
    "plt.ylim((0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rvss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1669dcdbca07850241162f699789cbb9152ec44917846b1cbad02e6b684a829"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
